{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "with open('dictionary.txt', 'r') as file:\n",
    "    dictionary = file.read().splitlines()\n",
    "\n",
    "df = pd.read_csv('24_train_2.csv',encoding='unicode_escape')\n",
    "\n",
    "# stemming tool from nltk\n",
    "stemmer = PorterStemmer()\n",
    "# a mapping dictionary that help remove punctuations\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def get_tokens(text):\n",
    "  # turn document into lowercase\n",
    "  lowers = text.lower()\n",
    "  # remove punctuations\n",
    "  no_punctuation = lowers.translate(remove_punctuation_map)\n",
    "  # tokenize document\n",
    "  tokens = nltk.word_tokenize(no_punctuation)\n",
    "  # remove stop words\n",
    "  filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "  # stemming process\n",
    "  stemmed = []\n",
    "  for item in filtered:\n",
    "      stemmed.append(stemmer.stem(item))\n",
    "  # final unigrams\n",
    "  unigrams = [word for word in stemmed if word in dictionary]\n",
    "  return unigrams\n",
    "\n",
    "#calling unigrams function\n",
    "df['Unigrams'] = df['Text'].apply(get_tokens)\n",
    "\n",
    "#calculating tf\n",
    "tf_matrix = np.zeros((len(df), len(dictionary)), dtype=float)\n",
    "\n",
    "for i, unigrams in enumerate(df['Unigrams']):\n",
    "    max_freq = 0\n",
    "    word_count = {}\n",
    "    for word in unigrams:\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "        max_freq = max(max_freq, word_count[word])\n",
    "    \n",
    "    for word in word_count:\n",
    "        if word in dictionary:\n",
    "            j = dictionary.index(word)\n",
    "            tf_matrix[i, j] = word_count[word] / max_freq\n",
    "\n",
    "#calculating idf\n",
    "idf_vector = np.zeros(len(dictionary), dtype=float)\n",
    "n_documents = len(df)\n",
    "\n",
    "for j, word in enumerate(dictionary):\n",
    "    doc_count = sum(tf_matrix[:, j] > 0)\n",
    "    if doc_count > 0:\n",
    "        idf_vector[j] = math.log(n_documents / doc_count)\n",
    "\n",
    "#calculating tfidf\n",
    "tfidf_matrix = tf_matrix * idf_vector\n",
    "tfidf_matrix=np.round(tfidf_matrix,4)\n",
    "\n",
    "output_file = 'matrix.txt'\n",
    "\n",
    "# Save the matrix to the file\n",
    "with open(output_file, 'w') as f:\n",
    "    for row in tfidf_matrix:\n",
    "        # Convert the row to a comma-separated string\n",
    "        row_string = ','.join([f\"{score:.4f}\" for score in row])\n",
    "        # Write the string to the file\n",
    "        f.write(row_string + '\\n')\n",
    "\n",
    "#sum tfidf\n",
    "category_tfidf_sum = {category: np.zeros(len(dictionary)) for category in df['Category'].unique()}\n",
    "category_word_count = {category: Counter() for category in df['Category'].unique()}\n",
    "category_doc_count = {category: 0 for category in df['Category'].unique()}\n",
    "\n",
    "for i, (unigrams, category) in enumerate(zip(df['Unigrams'], df['Category'])):\n",
    "    category_tfidf_sum[category] += tfidf_matrix[i]\n",
    "    category_word_count[category].update(unigrams)\n",
    "    category_doc_count[category] += 1\n",
    "\n",
    "#calculate average tfidf\n",
    "category_avg_tfidf = {}\n",
    "for category in category_tfidf_sum:\n",
    "    category_avg_tfidf[category] = category_tfidf_sum[category] / category_doc_count[category]\n",
    "\n",
    "#top 3 highest average tfidf\n",
    "top_words_by_tfidf = {}\n",
    "for category, avg_tfidf in category_avg_tfidf.items():\n",
    "    top_3_indices = np.argsort(avg_tfidf)[-3:][::-1]\n",
    "    top_words = [(dictionary[i], avg_tfidf[i]) for i in top_3_indices]\n",
    "    top_words_by_tfidf[category] = top_words\n",
    "\n",
    "#top 3 most frequent words in each category\n",
    "top_words_by_frequency = {}\n",
    "for category, word_count in category_word_count.items():\n",
    "    top_words = word_count.most_common(3)\n",
    "    top_words_by_frequency[category] = top_words\n",
    "\n",
    "#results\n",
    "print(\"\\n3 highest Average tfidf words in each category:\")\n",
    "for category, top_words in top_words_by_tfidf.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    for word, avg_tfidf in top_words:\n",
    "        print(f\"  {word}: {avg_tfidf:.4f}\")\n",
    "\n",
    "print(\"\\n3 most frequent words in each category:\")\n",
    "for category, top_words in top_words_by_frequency.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    for word, freq in top_words:\n",
    "        print(f\"  {word}: {freq}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
